
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J08bmgEWF8Gu2ecB_7hfuONepKCV5Zda
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

data = pd.read_csv("/content/Fraud.csv")

# Check for missing values
print(data.isnull().sum())

# No missing values in this case

# outliers using visualization or statistical methods
# We'll use box plots for illustration
plt.figure(figsize=(12, 8))
sns.boxplot(x='isFraud', y='amount', data=data)
plt.show()


# In this case, let's winsorize the amount column to handle outliers
from scipy.stats.mstats import winsorize
data['amount'] = winsorize(data['amount'], limits=[0.05, 0.05])

# Check correlation matrix
correlation_matrix = data.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.show()

# Train-Test Split
X = data.drop(['isFraud', 'isFlaggedFraud'], axis=1)
y = data['isFraud']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=[np.number]))
X_test_scaled = scaler.transform(X_test.select_dtypes(include=[np.number]))

# Build and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train_scaled, y_train)

# Ensure that X_train contains numerical features only
X_train_numeric = X_train.select_dtypes(include=[np.number])

# Check feature importance
feature_importance = pd.Series(model.feature_importances_, index=X_train_numeric.columns)
plt.figure(figsize=(10, 8))
feature_importance.nlargest(10).plot(kind='barh')
plt.show()

# Check for missing values in the training set
missing_values = X_train_numeric.isnull().sum()
print("Missing Values in Training Set:\n", missing_values)

# Handle missing values (if any)
# For example, you can use SimpleImputer to fill missing values with mean, median, etc.
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')  # You can choose a different strategy based on your data
X_train_numeric_imputed = pd.DataFrame(imputer.fit_transform(X_train_numeric), columns=X_train_numeric.columns)
X_test_numeric_imputed = pd.DataFrame(imputer.transform(X_test_scaled), columns=X_train_numeric.columns)

# Check feature importance after handling missing values
feature_importance = pd.Series(model.feature_importances_, index=X_train_numeric_imputed.columns)
plt.figure(figsize=(10, 8))
feature_importance.nlargest(10).plot(kind='barh')
plt.show()

# Check for missing values in the target variable
missing_values_y = y_test.isnull().sum()
print("Missing Values in Target Variable (y_test):", missing_values_y)

# Handle missing values (if any)
# In this case, it's uncommon to have missing values in the target variable
# If there are any, investigate why they are present and handle them appropriately

# Handle missing values in the target variable (if any)
if missing_values_y > 0:
    missing_indices = y_test[y_test.isnull()].index

    # Exclude rows with missing values from X_test_numeric_imputed and y_test
    X_test_numeric_imputed = X_test_numeric_imputed.loc[~X_test_numeric_imputed.index.isin(missing_indices)]
    y_test = y_test.dropna()

# Ensure that the lengths of X_test_numeric_imputed and y_test match
if len(X_test_numeric_imputed) != len(y_test):
    # If not, align the indices
    common_indices = X_test_numeric_imputed.index.intersection(y_test.index)
    X_test_numeric_imputed = X_test_numeric_imputed.loc[common_indices]
    y_test = y_test.loc[common_indices]

# Now, re-run the model evaluation steps
y_pred = model.predict(X_test_numeric_imputed)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Classification Report
print("Classification Report:\n", classification_report(y_test, y_pred))
